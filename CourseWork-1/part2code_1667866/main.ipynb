{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#important imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\enghr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created  <built-in function dir>\n"
     ]
    }
   ],
   "source": [
    "from Constants import*\n",
    "from helpers import PopulateCsvFile, RequestValue, CreateDir\n",
    "from MLHelpers import InitDataFrame, SplitDataFrame, ExcelAndShowCase\n",
    "from Training import TrainModels\n",
    "from Evaluation import EvaluateModels, EvaluateString\n",
    "from TrainingCVNonOptimized import TrainModelsOnCvNonOptimized\n",
    "from TrainingCVOptimized import TrainModelsCVOptimized\n",
    "CreateDir(\"Results\")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # \"error\", \"ignore\", \"always\", \"default\", \"module\" or \"once\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "init csv file with all raw data and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created  <built-in function dir>\n",
      "a total of  0  Articles in c:\\Users\\enghr\\Documents\\GitHub\\C1667866-CMT316\\CourseWork-1\\part2code_1667866/datasets_coursework1/bbc  have been sucessfully read/write\n",
      "a total of  510  Articles in c:\\Users\\enghr\\Documents\\GitHub\\C1667866-CMT316\\CourseWork-1\\part2code_1667866/datasets_coursework1/bbc\\business  have been sucessfully read/write\n",
      "a total of  386  Articles in c:\\Users\\enghr\\Documents\\GitHub\\C1667866-CMT316\\CourseWork-1\\part2code_1667866/datasets_coursework1/bbc\\entertainment  have been sucessfully read/write\n",
      "a total of  417  Articles in c:\\Users\\enghr\\Documents\\GitHub\\C1667866-CMT316\\CourseWork-1\\part2code_1667866/datasets_coursework1/bbc\\politics  have been sucessfully read/write\n",
      "a total of  511  Articles in c:\\Users\\enghr\\Documents\\GitHub\\C1667866-CMT316\\CourseWork-1\\part2code_1667866/datasets_coursework1/bbc\\sport  have been sucessfully read/write\n",
      "a total of  401  Articles in c:\\Users\\enghr\\Documents\\GitHub\\C1667866-CMT316\\CourseWork-1\\part2code_1667866/datasets_coursework1/bbc\\tech  have been sucessfully read/write\n"
     ]
    }
   ],
   "source": [
    "PopulateCsvFile(RequestValue(variablesDict, \"rawDataPath\"), RequestValue(variablesDict, \"targetCsvFile\"), \n",
    "                RequestValue(variablesDict, \"fieldNames\") , RequestValue(variablesDict, \"encodingType\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#init dataframe, split into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inits dataframe\n",
    "mainDataFrame = InitDataFrame(RequestValue(variablesDict, \"targetCsvFile\"), \n",
    "                              RequestValue(variablesDict, \"encodingType\") )\n",
    "\n",
    "\n",
    "    #split training and validation\n",
    "xTrain, xValid, yTrain, yValid = SplitDataFrame(mainDataFrame, \n",
    "                                                RequestValue(variablesDict, \"testSize\"), RequestValue(variablesDict, \"randomSeed\"))\n",
    "\n",
    "                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xTrain len:  1780 \n",
      "xValid len:  445 \n",
      "yTrain len:  1780 \n",
      "yValid len:  445\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nxTrain len: \",len(xTrain), \"\\nxValid len: \",len(xValid), \"\\nyTrain len: \", len(yTrain), \"\\nyValid len: \" , len(yValid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#train models on features without cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created  <built-in function dir>\n",
      "Created  <built-in function dir>\n",
      "Created  <built-in function dir>\n",
      "Created  <built-in function dir>\n"
     ]
    }
   ],
   "source": [
    "#arguments = (modelsDict, featuresDict, xTrain, yTrain,kFeatures)\n",
    "TrainModels(modeslDictionary, nonOpFeaturesDictionary, xTrain, yTrain, RequestValue(variablesDict, \"kFeatures\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Evaluate models against validation/test set returns data into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal-LogisticRegression-CountVectorizer.joblib  has been evaluated against data.\n",
      "Normal-LogisticRegression-TFDIFChar.joblib  has been evaluated against data.\n",
      "Normal-LogisticRegression-TFDIFUnigram.joblib  has been evaluated against data.\n",
      "Normal-NaiveBayes-CountVectorizer.joblib  has been evaluated against data.\n",
      "Normal-NaiveBayes-TFDIFChar.joblib  has been evaluated against data.\n",
      "Normal-NaiveBayes-TFDIFUnigram.joblib  has been evaluated against data.\n",
      "Normal-SVM-CountVectorizer.joblib  has been evaluated against data.\n",
      "Normal-SVM-TFDIFChar.joblib  has been evaluated against data.\n",
      "Normal-SVM-TFDIFUnigram.joblib  has been evaluated against data.\n"
     ]
    }
   ],
   "source": [
    "normalEvaluationScores = EvaluateModels(xValid, yValid, \"normal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the following is dataframe of the evaluation results from multiple models against the defult settings of multiple features(see constants.py for further details on models and features)\n",
    "this operation is without cross validation and directly fits a pipeline wtih each model \n",
    "the dataframe is dumped into an excel sheet in cwd/results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ModelName</th>\n",
       "      <th>FeatureName</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NormalLogisticRegression</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.955056</td>\n",
       "      <td>0.954045</td>\n",
       "      <td>0.953180</td>\n",
       "      <td>0.955176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NormalLogisticRegression</td>\n",
       "      <td>TFDIFChar</td>\n",
       "      <td>0.723596</td>\n",
       "      <td>0.700329</td>\n",
       "      <td>0.695423</td>\n",
       "      <td>0.786893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NormalLogisticRegression</td>\n",
       "      <td>TFDIFUnigram</td>\n",
       "      <td>0.955056</td>\n",
       "      <td>0.954716</td>\n",
       "      <td>0.951858</td>\n",
       "      <td>0.959356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NormalNaiveBayes</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.959551</td>\n",
       "      <td>0.959168</td>\n",
       "      <td>0.960510</td>\n",
       "      <td>0.958578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NormalNaiveBayes</td>\n",
       "      <td>TFDIFChar</td>\n",
       "      <td>0.469663</td>\n",
       "      <td>0.277631</td>\n",
       "      <td>0.402787</td>\n",
       "      <td>0.397330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NormalNaiveBayes</td>\n",
       "      <td>TFDIFUnigram</td>\n",
       "      <td>0.955056</td>\n",
       "      <td>0.954552</td>\n",
       "      <td>0.952317</td>\n",
       "      <td>0.957590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NormalSVM</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.943820</td>\n",
       "      <td>0.943951</td>\n",
       "      <td>0.941993</td>\n",
       "      <td>0.946763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NormalSVM</td>\n",
       "      <td>TFDIFChar</td>\n",
       "      <td>0.898876</td>\n",
       "      <td>0.895553</td>\n",
       "      <td>0.893219</td>\n",
       "      <td>0.900434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NormalSVM</td>\n",
       "      <td>TFDIFUnigram</td>\n",
       "      <td>0.968539</td>\n",
       "      <td>0.968277</td>\n",
       "      <td>0.967483</td>\n",
       "      <td>0.969275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ModelName      FeatureName  accuracy        f1  precision  \\\n",
       "0  NormalLogisticRegression  CountVectorizer  0.955056  0.954045   0.953180   \n",
       "1  NormalLogisticRegression        TFDIFChar  0.723596  0.700329   0.695423   \n",
       "2  NormalLogisticRegression     TFDIFUnigram  0.955056  0.954716   0.951858   \n",
       "3          NormalNaiveBayes  CountVectorizer  0.959551  0.959168   0.960510   \n",
       "4          NormalNaiveBayes        TFDIFChar  0.469663  0.277631   0.402787   \n",
       "5          NormalNaiveBayes     TFDIFUnigram  0.955056  0.954552   0.952317   \n",
       "6                 NormalSVM  CountVectorizer  0.943820  0.943951   0.941993   \n",
       "7                 NormalSVM        TFDIFChar  0.898876  0.895553   0.893219   \n",
       "8                 NormalSVM     TFDIFUnigram  0.968539  0.968277   0.967483   \n",
       "\n",
       "     recall  \n",
       "0  0.955176  \n",
       "1  0.786893  \n",
       "2  0.959356  \n",
       "3  0.958578  \n",
       "4  0.397330  \n",
       "5  0.957590  \n",
       "6  0.946763  \n",
       "7  0.900434  \n",
       "8  0.969275  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ExcelAndShowCase(normalEvaluationScores, \"/normalEvaluationScores\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#train non optimized cross-validation and returns a dataframe of training scores and test scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    3.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    5.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    2.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    2.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    6.6s finished\n"
     ]
    }
   ],
   "source": [
    "nonOpTrainScores, nonOpTestScores = TrainModelsOnCvNonOptimized(modeslDictionary,nonOpFeaturesDictionary, mainDataFrame, RequestValue(variablesDict, \"kFeatures\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the following is dataframe of the train and test results from multiple models against the defult settings of multiple features(see constants.py for further details on models and features) with non-optimized cross validation utilizing cross_validate from sklearn\n",
    "mean of train score for all folds for each model/clf and feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelName</th>\n",
       "      <th>featureName</th>\n",
       "      <th>AVGaccuracy</th>\n",
       "      <th>AVGf1</th>\n",
       "      <th>AVGprecision</th>\n",
       "      <th>AVGrecall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train-NaiveBayes</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.967866</td>\n",
       "      <td>0.967454</td>\n",
       "      <td>0.967262</td>\n",
       "      <td>0.967895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Train-NaiveBayes</td>\n",
       "      <td>TFDIFUnigram</td>\n",
       "      <td>0.949889</td>\n",
       "      <td>0.949861</td>\n",
       "      <td>0.954318</td>\n",
       "      <td>0.946891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Train-NaiveBayes</td>\n",
       "      <td>TFDIFChar</td>\n",
       "      <td>0.457079</td>\n",
       "      <td>0.260727</td>\n",
       "      <td>0.519074</td>\n",
       "      <td>0.399462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Train-LogisticRegression</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.999101</td>\n",
       "      <td>0.999128</td>\n",
       "      <td>0.999173</td>\n",
       "      <td>0.999084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Train-LogisticRegression</td>\n",
       "      <td>TFDIFUnigram</td>\n",
       "      <td>0.957079</td>\n",
       "      <td>0.957119</td>\n",
       "      <td>0.960321</td>\n",
       "      <td>0.954781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Train-LogisticRegression</td>\n",
       "      <td>TFDIFChar</td>\n",
       "      <td>0.731469</td>\n",
       "      <td>0.713043</td>\n",
       "      <td>0.802487</td>\n",
       "      <td>0.708977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Train-SVM</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.978653</td>\n",
       "      <td>0.978565</td>\n",
       "      <td>0.979502</td>\n",
       "      <td>0.977771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Train-SVM</td>\n",
       "      <td>TFDIFUnigram</td>\n",
       "      <td>0.979551</td>\n",
       "      <td>0.979468</td>\n",
       "      <td>0.980135</td>\n",
       "      <td>0.978953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Train-SVM</td>\n",
       "      <td>TFDIFChar</td>\n",
       "      <td>0.913486</td>\n",
       "      <td>0.911263</td>\n",
       "      <td>0.916112</td>\n",
       "      <td>0.908971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  modelName      featureName  AVGaccuracy     AVGf1  \\\n",
       "0          Train-NaiveBayes  CountVectorizer     0.967866  0.967454   \n",
       "1          Train-NaiveBayes     TFDIFUnigram     0.949889  0.949861   \n",
       "2          Train-NaiveBayes        TFDIFChar     0.457079  0.260727   \n",
       "3  Train-LogisticRegression  CountVectorizer     0.999101  0.999128   \n",
       "4  Train-LogisticRegression     TFDIFUnigram     0.957079  0.957119   \n",
       "5  Train-LogisticRegression        TFDIFChar     0.731469  0.713043   \n",
       "6                 Train-SVM  CountVectorizer     0.978653  0.978565   \n",
       "7                 Train-SVM     TFDIFUnigram     0.979551  0.979468   \n",
       "8                 Train-SVM        TFDIFChar     0.913486  0.911263   \n",
       "\n",
       "   AVGprecision  AVGrecall  \n",
       "0      0.967262   0.967895  \n",
       "1      0.954318   0.946891  \n",
       "2      0.519074   0.399462  \n",
       "3      0.999173   0.999084  \n",
       "4      0.960321   0.954781  \n",
       "5      0.802487   0.708977  \n",
       "6      0.979502   0.977771  \n",
       "7      0.980135   0.978953  \n",
       "8      0.916112   0.908971  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ExcelAndShowCase(nonOpTrainScores, \"/nonOpTrainScores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mean of test score for all folds for each model/clf and feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelName</th>\n",
       "      <th>featureName</th>\n",
       "      <th>AVGaccuracy</th>\n",
       "      <th>AVGf1</th>\n",
       "      <th>AVGprecision</th>\n",
       "      <th>AVGrecall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Test-NaiveBayes</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.938441</td>\n",
       "      <td>0.938179</td>\n",
       "      <td>0.939212</td>\n",
       "      <td>0.939793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test-NaiveBayes</td>\n",
       "      <td>TFDIFUnigram</td>\n",
       "      <td>0.925864</td>\n",
       "      <td>0.925539</td>\n",
       "      <td>0.935265</td>\n",
       "      <td>0.921461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Test-NaiveBayes</td>\n",
       "      <td>TFDIFChar</td>\n",
       "      <td>0.440905</td>\n",
       "      <td>0.249184</td>\n",
       "      <td>0.379192</td>\n",
       "      <td>0.385059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Test-LogisticRegression</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.935744</td>\n",
       "      <td>0.935788</td>\n",
       "      <td>0.937151</td>\n",
       "      <td>0.935799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Test-LogisticRegression</td>\n",
       "      <td>TFDIFUnigram</td>\n",
       "      <td>0.916426</td>\n",
       "      <td>0.917354</td>\n",
       "      <td>0.929035</td>\n",
       "      <td>0.912925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Test-LogisticRegression</td>\n",
       "      <td>TFDIFChar</td>\n",
       "      <td>0.684069</td>\n",
       "      <td>0.653725</td>\n",
       "      <td>0.765404</td>\n",
       "      <td>0.658444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Test-SVM</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.915516</td>\n",
       "      <td>0.914776</td>\n",
       "      <td>0.919049</td>\n",
       "      <td>0.913486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Test-SVM</td>\n",
       "      <td>TFDIFUnigram</td>\n",
       "      <td>0.922708</td>\n",
       "      <td>0.924097</td>\n",
       "      <td>0.928164</td>\n",
       "      <td>0.922982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Test-SVM</td>\n",
       "      <td>TFDIFChar</td>\n",
       "      <td>0.850361</td>\n",
       "      <td>0.847036</td>\n",
       "      <td>0.854870</td>\n",
       "      <td>0.846518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 modelName      featureName  AVGaccuracy     AVGf1  \\\n",
       "0          Test-NaiveBayes  CountVectorizer     0.938441  0.938179   \n",
       "1          Test-NaiveBayes     TFDIFUnigram     0.925864  0.925539   \n",
       "2          Test-NaiveBayes        TFDIFChar     0.440905  0.249184   \n",
       "3  Test-LogisticRegression  CountVectorizer     0.935744  0.935788   \n",
       "4  Test-LogisticRegression     TFDIFUnigram     0.916426  0.917354   \n",
       "5  Test-LogisticRegression        TFDIFChar     0.684069  0.653725   \n",
       "6                 Test-SVM  CountVectorizer     0.915516  0.914776   \n",
       "7                 Test-SVM     TFDIFUnigram     0.922708  0.924097   \n",
       "8                 Test-SVM        TFDIFChar     0.850361  0.847036   \n",
       "\n",
       "   AVGprecision  AVGrecall  \n",
       "0      0.939212   0.939793  \n",
       "1      0.935265   0.921461  \n",
       "2      0.379192   0.385059  \n",
       "3      0.937151   0.935799  \n",
       "4      0.929035   0.912925  \n",
       "5      0.765404   0.658444  \n",
       "6      0.919049   0.913486  \n",
       "7      0.928164   0.922982  \n",
       "8      0.854870   0.846518  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ExcelAndShowCase(nonOpTestScores, \"/nonOpTestScores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#train cv optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "Best model parms:\n",
      "Pipeline(steps=[('CountVectorizer',\n",
      "                 CountVectorizer(max_features=5000, token_pattern='\\\\w{1,}')),\n",
      "                ('feature-Selector',\n",
      "                 SelectKBest(k=350,\n",
      "                             score_func=<function chi2 at 0x000001F79A07FE50>)),\n",
      "                ('NaiveBayes', MultinomialNB())])\n",
      "Created  <built-in function dir>\n",
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n",
      "Best model parms:\n",
      "Pipeline(steps=[('TFDIFUnigram',\n",
      "                 TfidfVectorizer(max_features=5000, ngram_range=(1, 2),\n",
      "                                 token_pattern='\\\\w{1,}')),\n",
      "                ('feature-Selector',\n",
      "                 SelectKBest(k=350,\n",
      "                             score_func=<function chi2 at 0x000001F79A07FE50>)),\n",
      "                ('NaiveBayes', MultinomialNB())])\n",
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n",
      "Best model parms:\n",
      "Pipeline(steps=[('TFDIFChar',\n",
      "                 TfidfVectorizer(analyzer='char', max_features=5000,\n",
      "                                 ngram_range=(1, 2), token_pattern='\\\\w{1,}')),\n",
      "                ('feature-Selector',\n",
      "                 SelectKBest(k=350,\n",
      "                             score_func=<function chi2 at 0x000001F79A07FE50>)),\n",
      "                ('NaiveBayes', MultinomialNB())])\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "Best model parms:\n",
      "Pipeline(steps=[('CountVectorizer',\n",
      "                 CountVectorizer(max_features=5000, ngram_range=(1, 2),\n",
      "                                 token_pattern='\\\\w{1,}')),\n",
      "                ('feature-Selector',\n",
      "                 SelectKBest(k=350,\n",
      "                             score_func=<function chi2 at 0x000001F79A07FE50>)),\n",
      "                ('LogisticRegression', LogisticRegression())])\n",
      "Created  <built-in function dir>\n",
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n",
      "Best model parms:\n",
      "Pipeline(steps=[('TFDIFUnigram',\n",
      "                 TfidfVectorizer(max_features=5000, ngram_range=(1, 2),\n",
      "                                 token_pattern='\\\\w{1,}')),\n",
      "                ('feature-Selector',\n",
      "                 SelectKBest(k=350,\n",
      "                             score_func=<function chi2 at 0x000001F79A07FE50>)),\n",
      "                ('LogisticRegression', LogisticRegression())])\n",
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n",
      "Best model parms:\n",
      "Pipeline(steps=[('TFDIFChar',\n",
      "                 TfidfVectorizer(analyzer='char', max_features=5000,\n",
      "                                 ngram_range=(1, 2), token_pattern='\\\\w{1,}')),\n",
      "                ('feature-Selector',\n",
      "                 SelectKBest(k=350,\n",
      "                             score_func=<function chi2 at 0x000001F79A07FE50>)),\n",
      "                ('LogisticRegression', LogisticRegression())])\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "Best model parms:\n",
      "Pipeline(steps=[('CountVectorizer',\n",
      "                 CountVectorizer(max_features=5000, token_pattern='\\\\w{1,}')),\n",
      "                ('feature-Selector',\n",
      "                 SelectKBest(k=350,\n",
      "                             score_func=<function chi2 at 0x000001F79A07FE50>)),\n",
      "                ('SVM', SVC())])\n",
      "Created  <built-in function dir>\n",
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n",
      "Best model parms:\n",
      "Pipeline(steps=[('TFDIFUnigram',\n",
      "                 TfidfVectorizer(max_features=5000, ngram_range=(1, 2),\n",
      "                                 token_pattern='\\\\w{1,}')),\n",
      "                ('feature-Selector',\n",
      "                 SelectKBest(k=350,\n",
      "                             score_func=<function chi2 at 0x000001F79A07FE50>)),\n",
      "                ('SVM', SVC())])\n",
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n",
      "Best model parms:\n",
      "Pipeline(steps=[('TFDIFChar',\n",
      "                 TfidfVectorizer(analyzer='char', max_features=5000,\n",
      "                                 ngram_range=(1, 2), token_pattern='\\\\w{1,}')),\n",
      "                ('feature-Selector',\n",
      "                 SelectKBest(k=300,\n",
      "                             score_func=<function chi2 at 0x000001F79A07FE50>)),\n",
      "                ('SVM', SVC())])\n"
     ]
    }
   ],
   "source": [
    "opTrainScores, opTestScores = TrainModelsCVOptimized(modeslDictionary, featuresDictionary, xTrain, yTrain)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the following is dataframe of the test and train results from multiple models and features optimized with cross-validation and hyper param tuning utilizing graphsearchcv\n",
    "#mean of train score for all folds for each model/clf and feature using the best parms (from graph search cv from sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelName</th>\n",
       "      <th>featureName</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train-NaiveBayes</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.974157</td>\n",
       "      <td>0.973825</td>\n",
       "      <td>0.973264</td>\n",
       "      <td>0.974579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Train-NaiveBayes</td>\n",
       "      <td>TFDIFUnigram</td>\n",
       "      <td>0.953090</td>\n",
       "      <td>0.953075</td>\n",
       "      <td>0.957933</td>\n",
       "      <td>0.949898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Train-NaiveBayes</td>\n",
       "      <td>TFDIFChar</td>\n",
       "      <td>0.449439</td>\n",
       "      <td>0.258103</td>\n",
       "      <td>0.329800</td>\n",
       "      <td>0.394152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Train-LogisticRegression</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Train-LogisticRegression</td>\n",
       "      <td>TFDIFUnigram</td>\n",
       "      <td>0.961236</td>\n",
       "      <td>0.961425</td>\n",
       "      <td>0.964398</td>\n",
       "      <td>0.959225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Train-LogisticRegression</td>\n",
       "      <td>TFDIFChar</td>\n",
       "      <td>0.732581</td>\n",
       "      <td>0.717659</td>\n",
       "      <td>0.806454</td>\n",
       "      <td>0.711514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Train-SVM</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.979776</td>\n",
       "      <td>0.979888</td>\n",
       "      <td>0.980749</td>\n",
       "      <td>0.979182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Train-SVM</td>\n",
       "      <td>TFDIFUnigram</td>\n",
       "      <td>0.984549</td>\n",
       "      <td>0.984634</td>\n",
       "      <td>0.984941</td>\n",
       "      <td>0.984383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Train-SVM</td>\n",
       "      <td>TFDIFChar</td>\n",
       "      <td>0.912077</td>\n",
       "      <td>0.910329</td>\n",
       "      <td>0.916093</td>\n",
       "      <td>0.907682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  modelName      featureName  accuracy        f1  precision  \\\n",
       "0          Train-NaiveBayes  CountVectorizer  0.974157  0.973825   0.973264   \n",
       "1          Train-NaiveBayes     TFDIFUnigram  0.953090  0.953075   0.957933   \n",
       "2          Train-NaiveBayes        TFDIFChar  0.449439  0.258103   0.329800   \n",
       "3  Train-LogisticRegression  CountVectorizer  1.000000  1.000000   1.000000   \n",
       "4  Train-LogisticRegression     TFDIFUnigram  0.961236  0.961425   0.964398   \n",
       "5  Train-LogisticRegression        TFDIFChar  0.732581  0.717659   0.806454   \n",
       "6                 Train-SVM  CountVectorizer  0.979776  0.979888   0.980749   \n",
       "7                 Train-SVM     TFDIFUnigram  0.984549  0.984634   0.984941   \n",
       "8                 Train-SVM        TFDIFChar  0.912077  0.910329   0.916093   \n",
       "\n",
       "     recall  \n",
       "0  0.974579  \n",
       "1  0.949898  \n",
       "2  0.394152  \n",
       "3  1.000000  \n",
       "4  0.959225  \n",
       "5  0.711514  \n",
       "6  0.979182  \n",
       "7  0.984383  \n",
       "8  0.907682  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ExcelAndShowCase(opTrainScores, \"/opTrainScores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mean of test score for all folds for each model/clf and feature using the best parms (from graph search cv from sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelName</th>\n",
       "      <th>featureName</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train-NaiveBayes</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.961791</td>\n",
       "      <td>0.961334</td>\n",
       "      <td>0.961116</td>\n",
       "      <td>0.961948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Train-NaiveBayes</td>\n",
       "      <td>TFDIFUnigram</td>\n",
       "      <td>0.941570</td>\n",
       "      <td>0.940998</td>\n",
       "      <td>0.945712</td>\n",
       "      <td>0.938098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Train-NaiveBayes</td>\n",
       "      <td>TFDIFChar</td>\n",
       "      <td>0.444945</td>\n",
       "      <td>0.254447</td>\n",
       "      <td>0.194689</td>\n",
       "      <td>0.390061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Train-LogisticRegression</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.955052</td>\n",
       "      <td>0.954674</td>\n",
       "      <td>0.955351</td>\n",
       "      <td>0.954510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Train-LogisticRegression</td>\n",
       "      <td>TFDIFUnigram</td>\n",
       "      <td>0.950560</td>\n",
       "      <td>0.950450</td>\n",
       "      <td>0.953669</td>\n",
       "      <td>0.948181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Train-LogisticRegression</td>\n",
       "      <td>TFDIFChar</td>\n",
       "      <td>0.715726</td>\n",
       "      <td>0.701545</td>\n",
       "      <td>0.791203</td>\n",
       "      <td>0.694984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Train-SVM</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.937081</td>\n",
       "      <td>0.936091</td>\n",
       "      <td>0.938014</td>\n",
       "      <td>0.935076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Train-SVM</td>\n",
       "      <td>TFDIFUnigram</td>\n",
       "      <td>0.955057</td>\n",
       "      <td>0.955029</td>\n",
       "      <td>0.955553</td>\n",
       "      <td>0.955127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Train-SVM</td>\n",
       "      <td>TFDIFChar</td>\n",
       "      <td>0.869659</td>\n",
       "      <td>0.867578</td>\n",
       "      <td>0.876300</td>\n",
       "      <td>0.864851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  modelName      featureName  accuracy        f1  precision  \\\n",
       "0          Train-NaiveBayes  CountVectorizer  0.961791  0.961334   0.961116   \n",
       "1          Train-NaiveBayes     TFDIFUnigram  0.941570  0.940998   0.945712   \n",
       "2          Train-NaiveBayes        TFDIFChar  0.444945  0.254447   0.194689   \n",
       "3  Train-LogisticRegression  CountVectorizer  0.955052  0.954674   0.955351   \n",
       "4  Train-LogisticRegression     TFDIFUnigram  0.950560  0.950450   0.953669   \n",
       "5  Train-LogisticRegression        TFDIFChar  0.715726  0.701545   0.791203   \n",
       "6                 Train-SVM  CountVectorizer  0.937081  0.936091   0.938014   \n",
       "7                 Train-SVM     TFDIFUnigram  0.955057  0.955029   0.955553   \n",
       "8                 Train-SVM        TFDIFChar  0.869659  0.867578   0.876300   \n",
       "\n",
       "     recall  \n",
       "0  0.961948  \n",
       "1  0.938098  \n",
       "2  0.390061  \n",
       "3  0.954510  \n",
       "4  0.948181  \n",
       "5  0.694984  \n",
       "6  0.935076  \n",
       "7  0.955127  \n",
       "8  0.864851  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ExcelAndShowCase(opTestScores, \"/opTestScores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluation scores from xvalid and yvalid against the best models from the CVGraphsearch results (optimized cross-validaited models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OptimizedCV-LogisticRegression-CountVectorizer.joblib  has been evaluated against data.\n",
      "OptimizedCV-LogisticRegression-TFDIFChar.joblib  has been evaluated against data.\n",
      "OptimizedCV-LogisticRegression-TFDIFUnigram.joblib  has been evaluated against data.\n",
      "OptimizedCV-NaiveBayes-CountVectorizer.joblib  has been evaluated against data.\n",
      "OptimizedCV-NaiveBayes-TFDIFChar.joblib  has been evaluated against data.\n",
      "OptimizedCV-NaiveBayes-TFDIFUnigram.joblib  has been evaluated against data.\n",
      "OptimizedCV-SVM-CountVectorizer.joblib  has been evaluated against data.\n",
      "OptimizedCV-SVM-TFDIFChar.joblib  has been evaluated against data.\n",
      "OptimizedCV-SVM-TFDIFUnigram.joblib  has been evaluated against data.\n"
     ]
    }
   ],
   "source": [
    "opEvalScores = EvaluateModels(xValid, yValid, \"optimized\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data evaluation scores from xvalid and yvalid against the best models from the CVGraphsearch results (optimized cross-validaited models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ModelName</th>\n",
       "      <th>FeatureName</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OptimizedCVLogisticRegression</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.957303</td>\n",
       "      <td>0.956713</td>\n",
       "      <td>0.955833</td>\n",
       "      <td>0.957925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OptimizedCVLogisticRegression</td>\n",
       "      <td>TFDIFChar</td>\n",
       "      <td>0.768539</td>\n",
       "      <td>0.760863</td>\n",
       "      <td>0.749014</td>\n",
       "      <td>0.822425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OptimizedCVLogisticRegression</td>\n",
       "      <td>TFDIFUnigram</td>\n",
       "      <td>0.957303</td>\n",
       "      <td>0.956957</td>\n",
       "      <td>0.955435</td>\n",
       "      <td>0.959568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OptimizedCVNaiveBayes</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.964045</td>\n",
       "      <td>0.963738</td>\n",
       "      <td>0.964926</td>\n",
       "      <td>0.962972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OptimizedCVNaiveBayes</td>\n",
       "      <td>TFDIFChar</td>\n",
       "      <td>0.474157</td>\n",
       "      <td>0.282924</td>\n",
       "      <td>0.407032</td>\n",
       "      <td>0.596615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>OptimizedCVNaiveBayes</td>\n",
       "      <td>TFDIFUnigram</td>\n",
       "      <td>0.957303</td>\n",
       "      <td>0.956886</td>\n",
       "      <td>0.955429</td>\n",
       "      <td>0.958855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>OptimizedCVSVM</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.943820</td>\n",
       "      <td>0.943422</td>\n",
       "      <td>0.942525</td>\n",
       "      <td>0.945290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>OptimizedCVSVM</td>\n",
       "      <td>TFDIFChar</td>\n",
       "      <td>0.901124</td>\n",
       "      <td>0.899692</td>\n",
       "      <td>0.897492</td>\n",
       "      <td>0.903073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>OptimizedCVSVM</td>\n",
       "      <td>TFDIFUnigram</td>\n",
       "      <td>0.966292</td>\n",
       "      <td>0.965769</td>\n",
       "      <td>0.966058</td>\n",
       "      <td>0.965601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ModelName      FeatureName  accuracy        f1  \\\n",
       "0  OptimizedCVLogisticRegression  CountVectorizer  0.957303  0.956713   \n",
       "1  OptimizedCVLogisticRegression        TFDIFChar  0.768539  0.760863   \n",
       "2  OptimizedCVLogisticRegression     TFDIFUnigram  0.957303  0.956957   \n",
       "3          OptimizedCVNaiveBayes  CountVectorizer  0.964045  0.963738   \n",
       "4          OptimizedCVNaiveBayes        TFDIFChar  0.474157  0.282924   \n",
       "5          OptimizedCVNaiveBayes     TFDIFUnigram  0.957303  0.956886   \n",
       "6                 OptimizedCVSVM  CountVectorizer  0.943820  0.943422   \n",
       "7                 OptimizedCVSVM        TFDIFChar  0.901124  0.899692   \n",
       "8                 OptimizedCVSVM     TFDIFUnigram  0.966292  0.965769   \n",
       "\n",
       "   precision    recall  \n",
       "0   0.955833  0.957925  \n",
       "1   0.749014  0.822425  \n",
       "2   0.955435  0.959568  \n",
       "3   0.964926  0.962972  \n",
       "4   0.407032  0.596615  \n",
       "5   0.955429  0.958855  \n",
       "6   0.942525  0.945290  \n",
       "7   0.897492  0.903073  \n",
       "8   0.966058  0.965601  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ExcelAndShowCase(opEvalScores, \"/opEvalScores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal-LogisticRegression-CountVectorizer.joblib  predicted: ['sport']\n",
      "Normal-LogisticRegression-TFDIFChar.joblib  predicted: ['sport']\n",
      "Normal-LogisticRegression-TFDIFUnigram.joblib  predicted: ['sport']\n",
      "Normal-NaiveBayes-CountVectorizer.joblib  predicted: ['politics']\n",
      "Normal-NaiveBayes-TFDIFChar.joblib  predicted: ['sport']\n",
      "Normal-NaiveBayes-TFDIFUnigram.joblib  predicted: ['sport']\n",
      "Normal-SVM-CountVectorizer.joblib  predicted: ['sport']\n",
      "Normal-SVM-TFDIFChar.joblib  predicted: ['sport']\n",
      "Normal-SVM-TFDIFUnigram.joblib  predicted: ['sport']\n",
      "OptimizedCV-LogisticRegression-CountVectorizer.joblib  predicted: ['sport']\n",
      "OptimizedCV-LogisticRegression-TFDIFChar.joblib  predicted: ['sport']\n",
      "OptimizedCV-LogisticRegression-TFDIFUnigram.joblib  predicted: ['sport']\n",
      "OptimizedCV-NaiveBayes-CountVectorizer.joblib  predicted: ['politics']\n",
      "OptimizedCV-NaiveBayes-TFDIFChar.joblib  predicted: ['sport']\n",
      "OptimizedCV-NaiveBayes-TFDIFUnigram.joblib  predicted: ['sport']\n",
      "OptimizedCV-SVM-CountVectorizer.joblib  predicted: ['sport']\n",
      "OptimizedCV-SVM-TFDIFChar.joblib  predicted: ['sport']\n",
      "OptimizedCV-SVM-TFDIFUnigram.joblib  predicted: ['sport']\n"
     ]
    }
   ],
   "source": [
    "EvaluateString('IAAF launches fight against drugsThe IAAF - athletics world governing body - has met anti-doping officials, coaches and athletes to co-ordinate the fight against drugs in sport.Two task forces have been set up to examine doping and nutrition issues. It was also agreed that a programme to de-mystify the issue to athletes, the public and the media was a priority. Nothing was decided to change things - it was more to have a forum of the stakeholders allowing them to express themselves, said an IAAF spokesman. Getting everyone together gave us a lot of food for thought. About 60 people attended Sundays meeting in Monaco, including IAAF chief Lamine Diack and Namibian athlete Frankie Fredericks, now a member of the Athletes Commission. I am very happy to see you all, members of the athletics family, respond positively to the IAAF call to sit together and discuss what more we can do in the fight against doping, said Diack. We are the leading Federation in this field and it is our duty to keep our sport clean. The two task forces will report back to the IAAF Council, at its April meeting in Qatar.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7a895bd21b1a1d2731361ff59fc708282165d760aa0414dacdfeb3d2c9f175cf"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
